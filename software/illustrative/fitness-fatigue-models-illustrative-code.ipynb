{"cells":[{"metadata":{},"cell_type":"markdown","source":"Fitness Fatigue Models Illustrative Code\n=========================================\n\nThis is a companion notebook illustrating the fitness fatigue models discussed in our review series. It is a Kaggle Notebook with dependencies on data and scripts hosted on Kaggle.com. To run or edit this notebook, please visit the latest [Kaggle version](https://www.kaggle.com/baogorek/fitness-fatigue-models-illustrative-code) (if you are not already on Kaggle.com!).\n\n## Dependencies\n - [example_loads.csv](https://www.kaggle.com/baogorek/example-training-loads), a data set of example training loads created by @bsh2020.\n - [ffmfunctions.R](https://www.kaggle.com/baogorek/ffmfunctions), an R script containing functions relevant to the Fitness Fatigue model and variations discussed in our review papers\n "},{"metadata":{"_uuid":"051d70d956493feee0c6d64651c6a088724dca2a","_execution_state":"idle","trusted":true},"cell_type":"code","source":"# These paths are relative to Kaggle servers\nsource(\"../usr/lib/ffmfunctions/ffmfunctions.R\")\nexample_loads <- read.csv('../input/example-training-loads/example_loads.csv')\n\nset.seed(523445)  # Seed for reproducible output","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training loads\n\nIn this research, the raw training loads $\\omega^i$ are taken to be exogenous, i.e., coming from some predetermined plan, not a downstream impact of actual performance. It is represented in the code as `w`.\n\nAs noted in the dependencies, this notebook is accompied by an extensive training load dataset, which uses real exercises and separates upper body from lower body training impulses. These may be used below by choosing `training_type` to be either `\"upper body\"` or `\"lower body\"`. In addition there is also a fully synthetic option, `\"synthetic\"` that creates variation oportunistically, such as a long rest in the middle of the program so that fitness has time to fade. \n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# The Training Plan -----------------------------------------------------------\n\n# \"upper body\", \"lower body\", \"synthetic\"\ntraining_type <- \"upper body\" \n\nif (training_type == \"synthetic\") {\n  w <- rep(c(seq(10, 50), rep(20, 14)), 5)\n  w <- c(w, rep(0, 100), w)  #  Adding long rest!\n} else if (training_type == \"upper body\") {\n  w <- as.numeric(example_loads$tl_upper_fitness)\n} else if (training_type == \"lower body\") {\n  w <- as.numeric(example_loads$tl_lower_fitness)\n}\n\nplot(w, main = \"Training impulses for this demonstration\", xlab = \"time\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## The Basic Model\n\nThe basic 5-parameter Fitness Fatigue Model from our review is:\n\n$$\n\\text{E}(p_n | \\omega_1, \\ldots, \\omega_{n-1}) = p^{\\star} + k_g \\sum_{i=1}^{n-1} \\omega_i \\cdot e^{-\\frac{(n-i)}{\\tau_g}}\n - k_h \\sum_{i=1}^{n-1} \\omega_i \\cdot e^{-\\frac{(n-i)}{\\tau_h}}.\n$$\nAssuming Gaussian error, there is a 6th parameter, $\\sigma$, as\n$$\n\\epsilon_n \\text{ are i.i.d. } N(0, \\sigma^2).\n$$\n\nIn this section's code blocks, we will instantiate it, simulate from it, predict with it, and estimate unknown parameters using both gradient descent (with analytical gradients) and the L-BFGS-B algorithm."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Basic FFM -------------------------------------------------------------------\nffm_basic <- create_ffm_model(p_star = 400, k_g = 1, k_h = 3, tau_g = 60,\n                              tau_h = 15, sigma = 20)\n\nprint(ffm_basic)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df <- simulate(ffm_basic, w)\n\n# Predictions with true parameters\npred_true_df <- make_predictions(ffm_basic, w)\nplot(df$y, main = \"Simulated data with FFM predictions (true parameters)\")\npoints(pred_true_df$y_hat, col = 'blue')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Estimation in the basic model\nBelow we approach estimation of the unknown parameters of the basic Fitness Fatigue Model. As this is a non-convex estimation problem, good starting values are important. In our review, we describe an approach to data-driven starting values. This is implemented below. Note that the initialization results in a valid model in itself.\n\nFor the basic model, the inputs to the initialization are the data set and a course grid of potential time constants. These have default values but are specified below for transparency."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Estimating basic model, first get starting values from data set\nffm_from_data <- initialize_ffm_from_data(df, tau_g_seq = c(10, 50, 90),\n                                          tau_h_seq = c(5, 10, 20))\nprint(ffm_from_data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Maximum Likelihood Estimation\nMaximum Likelihood Estimation is performed with R's base `optim` function using the L-BFGS-B algorithm. The method of choosing starting values and upper and lower bounds is described in the review."},{"metadata":{"trusted":true},"cell_type":"code","source":"# One-shot maximum likelihood using L-BFGS-B\nffm_ml <- maximize_likelihood(ffm_from_data, df)\nprint(ffm_ml)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Gradient Descent\nThe gradient vector of the sum of squared residuals with respect to the fitness fatigue model is analytically tractible and may be used in a gradient descent algorithm. This method is included for comparison with the L-BFGS-G method used in R's base `optim` function. While it is possible to reduce the error dramatically from an intial condition, scaling is important.\n\nThis procedure normalizes the gradient, then applies individual scaling of the parameters before applying the usual $\\lambda$ tuning rate parameter (See [jermwatt.github.io](https://jermwatt.github.io/machine_learning_refined/notes/3_First_order_methods/3_9_Normalized.html) for an explanation.) It may be necessary to run the algorithm multiple times with different scalings and values of $\\lambda$. The method is thus\n\n$$\n\\theta_k^{\\star} = \\theta_{k - 1}^{\\star} - \\lambda \\frac{\\nabla g(\\theta_{k - 1})}{\\Vert \\nabla g(\\theta_{k - 1}) \\Vert_2 }\n$$\n\nwhere $\\theta$ are the 5 unknown model expectation parameters (i.e., not including error variance), $\\theta_k^{\\star}$ is $\\theta$ after elementwise division with a parameter scaling vector (`parscale` below), and $g(\\cdot)$ is the residual mean squared error function.\n\nFor demonstration purposes, the starting values will be strategically far away from their true values. As the user will see, it's challenging to match the performance of L-BFGS-B, and multiple rescalings are necessary. Note the parameters that move and the ones that don't"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Demonstration - to get feel for Gradient Descent\n\nffm_close <- create_ffm_model(p_star = 385, k_g = .5, k_h = 2.5, tau_g = 52,\n                              tau_h = 12, sigma = 15)\n\n# Initial try - note that p_star isn't moving much\nffm_gd <- increase_likelihood_by_gradient(ffm_close, df, reps = 1000,\n                                          lambda = .001, thin = 100)\n\n# Adjust parscale so that p_star moves\nffm_gd <- increase_likelihood_by_gradient(ffm_gd, df, reps = 2000,\n                                          lambda = .001, thin = 200,\n                                          parscale = c(.001, 4, 1, .05, .25))\nprint(ffm_gd)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Incorporating initial values\n\nTo the basic 5-parameter Fitness Fatigue Model, we now relax the assumption of zero initial fitness and fatigue effects and add the parameters $q_g$ and $q_h$. These have the interpretation of fitness and fatigue present at time $i=0$ with a zero training impulse at time $i=0$.\n\n$$\n\\begin{align}\n\\text{E}(p_n | \\omega_1, \\ldots, \\omega_{n-1}) = p^{\\star} &+ k_g \\sum_{i=1}^{n-1} \\omega_i \\cdot e^{-\\frac{(n-i)}{\\tau_g}}\n - k_h \\sum_{i=1}^{n-1} \\omega_i \\cdot e^{-\\frac{(n-i)}{\\tau_h}} \\\\\n &+ q_g \\cdot e^ {-\\frac{n}{\\tau_g}} + q_h \\cdot e ^ {-\\frac{n}{\\tau_h}}.\n\\end{align}\n$$\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"ffm_add_initial <- create_ffm_model(p_star = 400, k_g = 1, k_h = 3, tau_g = 60,\n                                    tau_h = 15, sigma = 20, q_g = 500, q_h = 250)\nprint(ffm_add_initial)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Visual Confirmation of non-zero offsets\nIn the data frame head and plots below, confirm that fitness and fatigue have non-zero offsets."},{"metadata":{"trusted":true},"cell_type":"code","source":"df <- simulate(ffm_add_initial, w)\nhead(df, 5)  # Look for fitness and fatigue to be around their starting values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# See the initial values at work\nplot(df$fitness, main = \"fitness\", xlab = \"time\")\nplot(df$fatigue, main = \"fatigue\", xlab = \"time\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ffm_from_data <- initialize_ffm_from_data(df, estimate_initial = TRUE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ffm_ml <- maximize_likelihood(ffm_from_data, df, tune_initial = TRUE)\nprint(ffm_ml)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predictions with estimated model\npred_df <- make_predictions(ffm_ml, w)\nplot(df$y, main = \"predictions vs data for initial values model\")\npoints(pred_df$y_hat, col = 'red')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## The Variable Dose-Response (VDR) Model\n\nWe now relax the assumption that the daily increase in fatigue depends only on the previous workout. In the variable dose-response (VDR) model, the daily increase to fatigue may depends on past training loads in an exponentially decaying manner.\n$$\n\\begin{align}\n\\text{E}(p_n | \\omega_1, \\ldots, \\omega_{n-1}) = p^{\\star} &+ k_g \\sum_{i=1}^{n-1} \\omega_i \\cdot e^{-\\frac{(n-i)}{\\tau_g}}\n - k_h \\sum_{i=1}^{n-1} k_{h_2} ^ i \\cdot e^{-\\frac{(n-i)}{\\tau_h}} \\\\\n &+ q_g \\cdot e^ {-\\frac{n}{\\tau_g}} + q_h \\cdot e ^ {-\\frac{n}{\\tau_h}},\n\\end{align}\n$$\n\nwhere\n$$\nk_{h_2} ^ i = \\sum_{j=1}^i \\omega_j \\cdot e^{-\\frac{(i-j)}{\\tau_{h_2}}}.\n$$\n\nBelow, notice how we brough down the value of $k_h$ from 3 to 1.5. If you set it at 3, you'll be in for some massive swings as fatigue now accumulates over multiple days."},{"metadata":{"trusted":true},"cell_type":"code","source":"ffm_vdr <- create_ffm_model(p_star = 400, k_g = 1, k_h = 1.5, tau_g = 60,\n                            tau_h = 15, sigma = 20,\n                            tau_h2 = 3, \n                            q_g = 300, q_h = 250)\nprint(ffm_vdr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df <- simulate(ffm_vdr, w)\nhead(df, 5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fatigue can get pretty large with tau_h and tau_h2\nplot(df$fitness, main = \"Fitness with VDR\")\nplot(df$fatigue, main = \"Fatigue with VDR\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predictions with true parameters\npred_true_df <- make_predictions(ffm_vdr, w)\nplot(df$y, main = \"VDR simulated and predictions with true values\")\npoints(pred_true_df$y_hat, col = 'blue')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Estimation of VDR parameters\nNote that we include a time constant sequence for the new $\\tau_{h_2}$ parameter in `initialize_ffm_from_data`."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Specify tau_h2_seq for data-driven VDR starting values\nffm_from_data <- initialize_ffm_from_data(df,\n                                          tau_g_seq = c(10, 50, 80),\n                                          tau_h_seq = c(5, 10, 20),\n                                          tau_h2_seq = c(1, 2, 5, 10, 15),\n                                          estimate_initial = TRUE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# One-shot maximum likelihood using L-BFGS-B\nffm_ml <- maximize_likelihood(ffm_from_data, df, tune_initial = TRUE, tune_vdr = TRUE)\nprint(ffm_ml)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_df <- make_predictions(ffm_ml, w)\nplot(df$y, main = \"predictions in VDR & initial based on ML Fit\")\npoints(pred_df$y_hat, col = 'red')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Using the Hill function\nThe Hill function is defined as\n\n$$\nHill(\\omega) = \\kappa \\left( \\frac{\\omega^\\gamma}{\\delta^\\gamma + \\omega^\\gamma}\\right)\n$$\nand, when used as a transformation to the raw training inputs, may mitigate the non-linearity in the training dose-response profile. Below is a demonstration of the Hill function applied to the same raw inputs as before, first with the basic model and then with all the other optional parameters.\n\nThe model is thus:\n\n$$\n\\text{E}(p_n | \\omega_1, \\ldots, \\omega_{n-1}) = p^{\\star} + k_g \\sum_{i=1}^{n-1} \\omega_i^{\\star} \\cdot e^{-\\frac{(n-i)}{\\tau_g}}\n - k_h \\sum_{i=1}^{n-1} \\omega_i ^ {\\star} \\cdot e^{-\\frac{(n-i)}{\\tau_h}}\n$$\n\nwhere\n$$\n\\omega_j^{\\star} = \\kappa \\left( \\frac{\\omega_j^\\gamma}{\\delta^\\gamma + \\omega_j^\\gamma}\\right), j = 1, \\ldots, n.\n$$\n\nIn the following, $\\kappa$ is not estimated but instead set to 100. This parameter is not estimable from data since $k_g$ and $k_h$ can \"undo\" the multiplier from $\\kappa$. "},{"metadata":{"trusted":true},"cell_type":"code","source":"ffm_hill <- create_ffm_model(p_star = 400, k_g = 1, k_h = 3, tau_g = 60,\n                             tau_h = 15, sigma = 20,\n                             gamma = 2, delta = 10, kappa = 100)\nprint(ffm_hill)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"w_hill <- get_hill_transformed_training(ffm_hill, w)\nplot(w_hill ~ w, main = \"Simulation-specified Hill Transformation\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df <- simulate(ffm_hill, w)\nhead(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predictions with true model\npred_df <- make_predictions(ffm_hill, w)\nplot(df$y, main = \"Predictions with True Model\")\npoints(pred_df$y_hat, col = 'red')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Specify delta_seq and gamma_seq for data-driven hill starting values\nffm_from_data <- initialize_ffm_from_data(df,\n                                          tau_g_seq = c(10, 50, 80),\n                                          tau_h_seq = c(5, 10, 20),\n                                          delta_seq = c(.3, 1, 1.5, 5, 20),\n                                          gamma_seq = c(.3, 1, 2, 5, 20))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# One-shot maximum likelihood using L-BFGS-B\nffm_ml <- maximize_likelihood(ffm_from_data, df, tune_hill = TRUE)\nprint(ffm_ml)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Hill transformation analysis\nw_hill_ml <- get_hill_transformed_training(ffm_ml, w)\nplot(w_hill ~ w, \n     main = \"Hill transformation - True (black) & Est (blue )\")\npoints(w_hill_ml ~ w, col = 'blue')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predictions with estimated model\npred_df <- make_predictions(ffm_ml, w)\nplot(df$y, main = \"Predictions with Hill-estimated mode\")\npoints(pred_df$y_hat, col = 'red')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## \"The Works\" Model: VDR, Initial Values, and Hill transformation\nFitting a model based on two variables with ten parameters in the expectation is ambitious, but below we go for it. The model here is\n\n$$\n\\begin{align}\n\\text{E}(p_n | \\omega_1, \\ldots, \\omega_{n-1}) = p^{\\star} &+ k_g \\sum_{i=1}^{n-1} \\omega_i^{\\star} \\cdot e^{-\\frac{(n-i)}{\\tau_g}}\n - k_h \\sum_{i=1}^{n-1} k_{h_2} ^ i \\cdot e^{-\\frac{(n-i)}{\\tau_h}} \\\\\n &+ q_g \\cdot e^ {-\\frac{n}{\\tau_g}} + q_h \\cdot e ^ {-\\frac{n}{\\tau_h}},\n\\end{align}\n$$\n\nwhere\n$$\nk_{h_2} ^ i = \\sum_{j=1}^i \\omega_j^{\\star} \\cdot e^{-\\frac{(i-j)}{\\tau_{h_2}}}\n$$\nand \n$$\n\\omega_j^{\\star} = \\kappa \\left( \\frac{\\omega_j^\\gamma}{\\delta^\\gamma + \\omega_j^\\gamma}\\right), j = 1, \\ldots, n.\n$$\n\nAgain, $\\kappa$ is not estimated but instead set to 100 for convenience.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"ffm_the_works <- create_ffm_model(p_star = 400, k_g = 1, k_h = .9, tau_g = 60,\n                                  tau_h = 15, sigma = 20, tau_h2 = 3,\n                                  gamma = 2, delta = 10, kappa = 100,\n                                  q_g = 300, q_h = 250)\nprint(ffm_the_works)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"w_hill_the_works <- get_hill_transformed_training(ffm_the_works, w)\nplot(w_hill_the_works ~ w, main = \"Hill transformation\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df <- simulate(ffm_the_works, w)\nhead(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot(df$fitness, main = \"fitness\", xlab = \"time\")\nplot(df$fatigue, main = \"fatigue\", xlab = \"time\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_df <- make_predictions(ffm_the_works, w)\nplot(df$y, main = \"Simulated data and true model predictions\")\npoints(pred_df$y_hat, col = 'red')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Estimation in \"The Works\" model\nThe initialization routine gets more complex, as now the grid must include both $\\gamma$ and $\\delta$ sequences. While the grid has become very large, as each iteration is a closed form regression the starting value-generating procedure still returns fairly quickly."},{"metadata":{"trusted":true},"cell_type":"code","source":"ffm_from_data <- initialize_ffm_from_data(df,\n                                          tau_g_seq = c(10, 50, 80),\n                                          tau_h_seq = c(5, 10, 20),\n                                          tau_h2_seq = c(1, 2, 5, 10),\n                                          delta_seq = c(.3, 1, 1.5, 5, 20),\n                                          gamma_seq = c(.3, 1, 2, 5, 20),\n                                          estimate_initial = TRUE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ffm_ml <- maximize_likelihood(ffm_from_data, df, tune_initial = TRUE,\n                              tune_vdr = TRUE, tune_hill = TRUE)\nprint(ffm_ml)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predictions with estimated model\npred_df <- make_predictions(ffm_ml, w)\nplot(df$y, main = \"Predictions from ML-estimated 'The Works' model\")\npoints(pred_df$y_hat, col = 'red')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"w_hill_ml <- get_hill_transformed_training(ffm_ml, w)\nplot(w_hill ~ w, \n     main = \"Hill transformation - True (black) & Est (blue )\")\npoints(w_hill_ml ~ w, col = 'blue')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"ir","display_name":"R","language":"R"},"language_info":{"name":"R","codemirror_mode":"r","pygments_lexer":"r","mimetype":"text/x-r-source","file_extension":".r","version":"3.6.3"}},"nbformat":4,"nbformat_minor":4}